{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Comments https://www.blackwhitereadallover.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from random import randint\n",
    "from time import sleep \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravisolter/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: use options instead of chrome_options\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Setting up the Chrome webdriver\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless') #uncomment to not render driven browser during scrapping\n",
    "\n",
    "options.binary_location = \"/usr/bin/google-chrome\"\n",
    "chrome_driver_binary = \"/usr/local/bin/chromedriver\"\n",
    "#options.binary_location = \"C:/Program Files (x86)/Google/Chrome/Application/chrome.exe\"\n",
    "#chrome_driver_binary = \"C:/Users/Alek/chromedriver\"\n",
    "driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the Archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.blackwhitereadallover.com/archives/2015/6\n"
     ]
    }
   ],
   "source": [
    "# Create a list of archive URLs (Feb, 2007 - March, 2020)\n",
    "\n",
    "archive_periods = []\n",
    "\n",
    "for j in range(2007,2021):\n",
    "    for k in range(1,13):\n",
    "        single_period = 'https://www.blackwhitereadallover.com/archives/'+str(j)+'/'+str(k)\n",
    "        archive_periods.append(single_period)\n",
    "        ;\n",
    "        \n",
    "# Subsetting out some periods for which there are no articles\n",
    "active_archives = archive_periods[1:len(archive_periods)-8]\n",
    "\n",
    "#len(active_archives) #159\n",
    "\n",
    "#print(active_archives[100])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b852dbc953cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sleep between 1 and 3 seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_archives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## Collecting the article URLS from each archive page, storing in 'archive_links' list\n",
    "\n",
    "archive_links = []\n",
    "\n",
    "for u in range(98,len(archive_periods)):\n",
    "    print(u)\n",
    "    \n",
    "    sleep(randint(4, 7))  # sleep between 1 and 3 seconds\n",
    "    \n",
    "    driver.get(active_archives[u])\n",
    "    \n",
    "    \n",
    "    # Checking to see if 'Load More' button exists (for months with>30 articles) and if so clicking it\n",
    "    button = driver.find_elements_by_xpath(\"//button[contains(text(),'Load More')]\")\n",
    "    while len(button) > 0 :\n",
    "        button[0].click()  \n",
    "        sleep(7)\n",
    "        button = driver.find_elements_by_xpath(\"//button[contains(text(),'Load More')]\")\n",
    "\n",
    " \n",
    "    \n",
    "    # Retrieving number of articles from title \n",
    "    # OLD archive_title = driver.find_element_by_xpath('/html/body/div[1]/div[2]/h1')\n",
    "    archive_title = driver.find_element_by_xpath(\"//h1[contains(text(),'Archives for')]\")\n",
    "\n",
    "    #print(archive_title.text)\n",
    "    \n",
    "    start = archive_title.text.find('(')+1\n",
    "    start = archive_title.text[start:]\n",
    "    articles = int(start.replace(')',''))\n",
    "    #print(articles)\n",
    "    \n",
    "    \n",
    "    # Retrieving the article links themselves\n",
    "    for q in range(0,articles):\n",
    "        \n",
    "        article_link = driver.find_elements_by_css_selector('h2.c-entry-box--compact__title>a')\n",
    "        article_link = article_link[q].get_attribute('href')\n",
    "        \n",
    "    \n",
    "        archive_links.append(article_link) \n",
    "           \n",
    "    ;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quick write out of links for when/if the loop breaks\n",
    "\n",
    "#MyFile=open('archive_links_98_end.txt','w')\n",
    "\n",
    "#for element in archive_links:\n",
    "#     MyFile.write(element)\n",
    "#     MyFile.write('\\n')\n",
    "#MyFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-9839b8539056>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marchive_links_full\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m      \u001b[0mMyFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m      \u001b[0mMyFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mMyFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not int"
     ]
    }
   ],
   "source": [
    "# Binding together the resulting .txts. There are 6k articles in total\n",
    "\n",
    "links1 = pd.read_csv('archive_links_1_78.txt',header=None)\n",
    "links2 = pd.read_csv('archive_links_79_97.txt',header=None)\n",
    "links3 = pd.read_csv('archive_links_98_end.txt',header=None)\n",
    "\n",
    "links12 = links1.append(links2, ignore_index = True) \n",
    "archive_links_full = links12.append(links3, ignore_index = True)\n",
    "\n",
    "archive_links_full.head()\n",
    "\n",
    "archive_links_full.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning it back into a list\n",
    "archive_links_full = archive_links_full[0].to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging in to BRWAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging in to BWRAO to have access to comment recs\n",
    "\n",
    "driver.get(\"https://auth.voxmedia.com/login?return_to=https://www.blackwhitereadallover.com/\")\n",
    "\n",
    "element = WebDriverWait(driver, 100).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"p-text-input\"))\n",
    "    )\n",
    "\n",
    "username = driver.find_element_by_xpath('//*[@id=\"login[username]\"]')\n",
    "username.clear()\n",
    "username.send_keys(\"rsolter\")\n",
    "\n",
    "\n",
    "password = driver.find_element_by_xpath('//*[@id=\"login[password]\"]')\n",
    "password.clear()\n",
    "password.send_keys(\"pass123!\")\n",
    "\n",
    "\n",
    "button = driver.find_element_by_xpath('//*[@id=\"auth\"]/div/form/fieldset[3]/input')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have selenium wait until the BWRAO logo loads (therefore, has logged in properly)\n",
    "element = WebDriverWait(driver, 100).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"c-global-header__logo-large\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping relevant info from individual pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 6035\n",
      "1 of 6035\n",
      "2 of 6035\n",
      "3 of 6035\n",
      "4 of 6035\n",
      "5 of 6035\n",
      "6 of 6035\n",
      "7 of 6035\n",
      "8 of 6035\n",
      "9 of 6035\n",
      "10 of 6035\n",
      "11 of 6035\n",
      "12 of 6035\n",
      "13 of 6035\n",
      "14 of 6035\n",
      "15 of 6035\n",
      "16 of 6035\n",
      "17 of 6035\n",
      "18 of 6035\n",
      "19 of 6035\n",
      "20 of 6035\n",
      "21 of 6035\n",
      "22 of 6035\n",
      "23 of 6035\n",
      "24 of 6035\n",
      "25 of 6035\n",
      "26 of 6035\n",
      "27 of 6035\n",
      "28 of 6035\n",
      "29 of 6035\n",
      "30 of 6035\n",
      "31 of 6035\n",
      "32 of 6035\n",
      "33 of 6035\n",
      "34 of 6035\n",
      "35 of 6035\n",
      "36 of 6035\n",
      "37 of 6035\n",
      "38 of 6035\n",
      "39 of 6035\n",
      "40 of 6035\n",
      "41 of 6035\n",
      "42 of 6035\n",
      "43 of 6035\n",
      "44 of 6035\n",
      "45 of 6035\n",
      "46 of 6035\n",
      "47 of 6035\n",
      "48 of 6035\n",
      "49 of 6035\n",
      "50 of 6035\n",
      "51 of 6035\n",
      "52 of 6035\n",
      "53 of 6035\n",
      "54 of 6035\n",
      "55 of 6035\n",
      "56 of 6035\n",
      "57 of 6035\n",
      "58 of 6035\n",
      "59 of 6035\n",
      "60 of 6035\n",
      "61 of 6035\n",
      "62 of 6035\n",
      "63 of 6035\n",
      "64 of 6035\n",
      "65 of 6035\n",
      "66 of 6035\n",
      "67 of 6035\n",
      "68 of 6035\n",
      "69 of 6035\n",
      "70 of 6035\n",
      "71 of 6035\n",
      "72 of 6035\n",
      "73 of 6035\n",
      "74 of 6035\n",
      "75 of 6035\n",
      "76 of 6035\n",
      "77 of 6035\n",
      "78 of 6035\n",
      "79 of 6035\n",
      "80 of 6035\n",
      "81 of 6035\n",
      "82 of 6035\n",
      "83 of 6035\n",
      "84 of 6035\n",
      "85 of 6035\n",
      "86 of 6035\n",
      "87 of 6035\n",
      "88 of 6035\n",
      "89 of 6035\n",
      "90 of 6035\n",
      "91 of 6035\n",
      "92 of 6035\n",
      "93 of 6035\n",
      "94 of 6035\n",
      "95 of 6035\n",
      "96 of 6035\n",
      "97 of 6035\n",
      "98 of 6035\n",
      "99 of 6035\n",
      "100 of 6035\n",
      "101 of 6035\n",
      "102 of 6035\n",
      "103 of 6035\n",
      "104 of 6035\n",
      "105 of 6035\n",
      "106 of 6035\n",
      "107 of 6035\n",
      "108 of 6035\n",
      "109 of 6035\n",
      "110 of 6035\n",
      "111 of 6035\n",
      "112 of 6035\n",
      "113 of 6035\n",
      "114 of 6035\n",
      "115 of 6035\n",
      "116 of 6035\n",
      "117 of 6035\n",
      "118 of 6035\n",
      "119 of 6035\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: timeout: Timed out receiving message from renderer: -223.428\n  (Session info: headless chrome=80.0.3987.163)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-754f05501c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' of '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_links_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_links_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m## Grab article title, author\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: timeout: Timed out receiving message from renderer: -223.428\n  (Session info: headless chrome=80.0.3987.163)\n"
     ]
    }
   ],
   "source": [
    "## Gathering blog title, author, publish date and comment list and comment count from a the loop of 'archive_links'\n",
    "\n",
    "comments_df = pd.DataFrame()\n",
    "for k in range(0,len(archive_links_full)):\n",
    "\n",
    "    print(str(k)+' of '+str(len(archive_links_full)))\n",
    "    \n",
    "    driver.get(archive_links_full[k])\n",
    "\n",
    "    ## Grab article title, author\n",
    "\n",
    "    blog_title = driver.find_element_by_xpath('//*[@id=\"content\"]/article/div[1]/div[1]/div[2]/h1')\n",
    "    article_author = driver.find_element_by_xpath('//*[@id=\"content\"]/article/div[1]/div[1]/div[3]/span[1]/span[1]/a/span')\n",
    "    article_publish_date = driver.find_element_by_xpath('//*[@id=\"content\"]/article/div[1]/div[1]/div[3]/span[1]/span[2]/time')\n",
    "\n",
    "\n",
    "    #Check for comments, and load, then run everything\n",
    "    test = len(driver.find_elements_by_xpath('//*[@id=\"comments\"]'))\n",
    "    if test > 0:\n",
    "        sleep(2)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        element = WebDriverWait(driver, 100).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"c-comments__list\")))\n",
    "\n",
    "        #Find number of comments\n",
    "\n",
    "        n_comments = driver.find_element_by_xpath('//*[@id=\"comments\"]/div[1]/span/span')\n",
    "        n_comments = int(n_comments.text)\n",
    "\n",
    "\n",
    "        # Looping through all comments to gather comment title, comment body, poster, and number of recs\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        for i in range(1,n_comments+1):\n",
    "    \n",
    "            xpath = '//*[@id=\"comments\"]/div[2]/div['+str(i)+']'\n",
    "     \n",
    "            comment_title = driver.find_element_by_xpath(xpath + '/div[1]')\n",
    "            comment_body = driver.find_element_by_xpath(xpath + '/div[2]')\n",
    "    \n",
    "            # Generally, comment meta data is stored in the 3rd div except when commentors have a signature\n",
    "            # in which case the meta data is in the 4th div\n",
    "            \n",
    "            #recs aren't weren't put in till later, and I was too lazy to find out when\n",
    "            #so I just check if they exist first\n",
    "            test = driver.find_elements_by_xpath(xpath+'/div[3]/span[2]/button[2]/span[2]')\n",
    "            test2 = driver.find_elements_by_xpath(xpath+'/div[4]/span[2]/button[2]/span[2]')\n",
    "            \n",
    "\n",
    "            if driver.find_elements_by_xpath(xpath + '/div[4]'):\n",
    "                meta = driver.find_element_by_xpath(xpath+'/div[4]/span[1]')\n",
    "                meta = meta.text.split(' on ')\n",
    "                post_date = meta[1]\n",
    "                poster = meta[0].split(' by ')[1]\n",
    "    \n",
    "                if len(test2) > 0:\n",
    "                # Some comments have no recommendations\n",
    "                    if driver.find_elements_by_xpath(xpath + '/div[4]/span[2]/button[2]/span[2]'):\n",
    "                        recs = driver.find_element_by_xpath(xpath + '/div[4]/span[2]/button[2]/span[2]')\n",
    "                        recs = int(recs.text.replace('(','').replace(')',''))\n",
    "                    else:\n",
    "                        recs = 0\n",
    "            else:\n",
    "                meta = driver.find_element_by_xpath(xpath+'/div[3]/span[1]')\n",
    "                meta = meta.text.split(' on ')\n",
    "                post_date = meta[1]\n",
    "                poster = meta[0].split(' by ')[1]\n",
    "        \n",
    "                if len(test) >0:\n",
    "                # Some comments have no recommendations\n",
    "                    if driver.find_elements_by_xpath(xpath + '/div[3]/span[2]/button[2]/span[2]'):\n",
    "                        recs = driver.find_element_by_xpath(xpath + '/div[3]/span[2]/button[2]/span[2]')\n",
    "                        recs = int(recs.text.replace('(','').replace(')',''))\n",
    "                    else:\n",
    "                        recs = 0\n",
    "                        \n",
    "            if len(test) == 0 & len(test2) == 0:\n",
    "                recs = \"\"\n",
    "\n",
    "\n",
    "            comment = pd.DataFrame([comment_title.text,comment_body.text,poster,post_date.split('|')[0],\n",
    "                            post_date.split('|')[1],recs])\n",
    "            comments_df = pd.concat([comments_df,comment.T])\n",
    "    sleep(4)\n",
    "    ;\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating into data frame, exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    }
   ],
   "source": [
    "comments_df.columns = ['Comment Title','Comment Body','Poster','Date','Time','Recs']\n",
    "\n",
    "# Adding article title and author to comments df\n",
    "#comments_df.insert(0, 'Article', blog_title.text)\n",
    "#comments_df.insert(1, 'Author', article_author.text)\n",
    "#comments_df.insert(2, 'Publish Date', article_publish_date.text)\n",
    "\n",
    "\n",
    "comments_df.head()\n",
    "\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.to_csv('Comments_1_119.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
